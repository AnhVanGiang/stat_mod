---
title: "Assignment 3"
output:
  pdf_document:
    includes:
      in_header: preample.tex
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
library(knitr)
library(afex)
library(performance)
library(magrittr)
library(MASS)
library(ggplot2)
library(plyr)
library(EnvStats)
hook_output <- knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    n <- as.numeric(n)
    x <- unlist(stringr::str_split(x, "\n"))
    nx <- length(x) 
    x <- x[pmin(n,nx)]
    if(min(n) > 1)  
      x <- c(paste(options$comment, "[...]"), x)
    if(max(n) < nx) 
      x <- c(x, paste(options$comment, "[...]"))
    x <- paste(c(x, "\n"), collapse = "\n")
  }
  hook_output(x, options)
    })
```

## Question 1
### a) 
We have 

\begin{align*}
 \log{f(y; r, \lambda_i)} &= \log{y^{r - 1}} + \log{e^{-y/\lambda_i}} - \log{\lambda_{i}^r} - \log{\Gamma(x)}\\
&= (r - 1) \log{y} - \frac{y}{\lambda_i} - r\log{\lambda_i} - \log{\Gamma(x)}\\
&= (r - 1) \log{y} - y r \theta_i - r\log{\lambda_i}- \log{\Gamma(x)}\\
&= (r - 1) \log{y} - y r \theta_i - r\log{((r \theta_i)^{-1})} - \log{\Gamma(x)}\\
&= (r - 1) \log{y} - y r \theta_i + r\log(r \theta_i) - \log{\Gamma(x)} \\
&= (r - 1) \log{y} - y r \theta_i + r \log(r) + r\log(\theta_i)- \log{\Gamma(x)}\\
&= -yr \theta_i + r \log{\theta_i} + r \log(r) + (r - 1) \log{y} - \log{\Gamma(x)}\\
&= -r (y \theta_i - \log{\theta_i}) + r \log(r) + (r - 1) \log{y} - \log{\Gamma(x)}\\
&= \frac{y \theta_i - \log{\theta_i}}{-1/r} + r \log(r) + (r - 1) \log{y} - \log{\Gamma(x)}\\
&= \frac{y \theta_i - \log{\theta_i}}{-1/r} + \left( r\log{r} + (r-1)\log{y} - \log{\Gamma(r)} \right).
\end{align*}
Thus, it follows that $f(y;r,\lambda_i)$ belongs to the exponential family with 
$b(\theta_i) = \log{\theta_i}$, $\phi/A_i = -1/r$ with $\phi = 1/r$ and $A_i = -1$.  

### b) 
We have 
\[ b(\theta_i) = \log{\theta_i} \]
so $\ex{Y_i} = b^{\prime}(\theta_i) = \frac{1}{\theta_i} =r\lambda_i = \mu_i$. Similarly, 
\[ \text{Var}(Y_i) = b^{\prime\prime}(\theta_i) \phi/A_i = \frac{-1}{\theta_i^2} \frac{-1}{r} = \frac{1}{\theta_i^2 r} = \frac{r^2 \lambda_i^2}{r} = r\lambda_i^2.\]
Furthermore, the CLF $g(\mu_i) = (b^{\prime})^{-1}(\mu_i) = \frac{1}{\mu_i}.$

### c) 
We have the Pearson's statistic 
\begin{align*}
P &= \phi \sum_{i=1}^n \frac{(Y_i - \ex_{\hat{\beta}}Y_i)^2}{\text{Var}_{\hat{\beta}}(Y_i)}\\
&= \frac{1}{r}\sum_{i=1}^n \frac{\left( Y_i - \frac{1}{\hat{\theta}_i} \right)^2}{1/(\hat{\theta}_i^2 r)}\\
&= \frac{1}{r}\sum_{i=1}^n \frac{\left( \frac{Y_i \hat{\theta}_i}{ \hat{\theta}_i} - \frac{1}{\hat{\theta}_i} \right)^2}{1/(\hat{\theta}_i^2 r)}\\
&= \frac{1}{r}\sum_{i=1}^n \frac{\left(Y_i \hat{\theta}_i - 1 \right)^2}{\hat{\theta}_i^2/(\hat{\theta}_i^2 r)}\\
&= \frac{1}{r}\sum_{i=1}^n \frac{(Y_i \hat{\theta}_i)^2 - 2Y_i \hat{\theta}_i + 1}{\hat{\theta}_i^2/(\hat{\theta}_i^2 r)}\\
&= \sum_{i=1}^n \left( (Y_i \hat{\theta}_i)^2 - 2Y_i \hat{\theta}_i + 1 \right).
\end{align*}
Furthermore, $\tilde{\theta}_i = (b^{\prime})^{-1}(Y_i) = 1/Y_i$ then 
\begin{align*}
D &= 2 \sum_{i=1}^n A_i (Y_i (\tilde{\theta}_i - \hat{\theta}_i) - b(\tilde{\theta}_i) + b(\hat{\theta}_i))\\
&= -2 \sum_{i=1}^n \left(Y_i \left(\frac{1}{Y_i} - \hat{\theta}_i \right) - \log{\frac{1}{Y_i}} + \log{\hat{\theta}_i} \right)\\
&= -2 \sum_{i=1}^n \left(Y_i \left(\frac{1}{Y_i} - \hat{\theta}_i \right) + \log{Y_i} + \log{\hat{\theta}_i} \right)\\
&= -2 \sum_{i=1}^n (1 - Y_i \hat{\theta}_i + \log{Y_i} + \log{\hat{\theta}_i}).
\end{align*}
Finally, for the working matrix $\hat{W}$, 
\begin{align*}
\hat{w}_{ii} &= \frac{A_i}{[g^{\prime}(\mu_i)]^2 b^{\prime \prime}(\theta_i)}\\
&= \frac{1}{\frac{1}{\hat{\mu}_i^4} \frac{-1}{\hat{\theta}^2}}\\
&= \frac{1}{\hat{\theta}_i^4 \frac{-1}{\hat{\theta}^2}}\\
&= \frac{-1}{\hat{\theta}_i^2}. 
\end{align*}

## Question 2
### a) 
```{r, echo=FALSE, include=FALSE}
n = 18;
p = 2;

crit_val = qt(0.05/2, n-p-1, lower.tail = FALSE);
```
There are 18 observations. The estimated parameters $\hat{\beta }= (\hat{\beta}_0, \hat{\beta}_1, \hat{\beta}_2) = (-0.021, 0.017, 0.01)$. Similarly, $\tilde{\phi} = \frac{D_{\Omega}}{n - p - 1} = \frac{0.3}{18 - 2 - 1} = 0.02$. 
To test for $H_0: \beta_1 = 0$ against $H_1: \beta_1 \neq 0$, we compute 
$t_1 = \frac{\hat{\beta}_1}{\sqrt{\left(\hat{I}_F^{-1}\right)_{11}}} = \frac{0.017}{0.001} = 17$ where
$\left(\hat{I}_F^{-1}\right)_{11}$ is the square of the standard error of the first variable. 
Since the test statistic $t_1 = 17$ is larger than $t_{15;1-0.05/2} = 2.13$, we reject $H_0$. 
The $96\%$ confidence interval for $\beta_1$ is 
\[ \hat{\beta}_1 \pm t_{15;1-0.04/2} \sqrt{\left(\hat{I}_F^{-1}\right)_{11}} = 0.017 \pm 2.25 \times 0.01 = [-0.0055, 0.0395].   \]


### b) 
To investigate the relevance of the variables $X1$ and $X2$, it suffices to look 
at the corresponding $p$-values in the output table of the command $summary(model)$. 
This shows that the $p$-value of $X2$ is smaller than $0.05$ so we can not dismiss the 
relevance of $X2$. Similarly, we test for the relevance of $X1$ in a) and rejected the 
null hypothesis that $\beta_1 = 0$ so $X1$ is relevant. 

### c) 
If not given, the standard errors in the first table could have been recovered as 
the square root of the variance of the sample. If the estimates are given, then the 
$t$-values could be (approximately) recovered by the formula 
\[t_i = \frac{\hat{\beta}_i}{\sqrt{\left(\hat{I}_F^{-1}\right)_{ii}}} \]
where $\sqrt{\left(\hat{I}_F^{-1}\right)_{11}}$ is the standard error of the $i$ 
predictor. It follows that the $p$-values could be recovered from the test statistic and the degree
of freedom. Similarly, if the $t$-values are given, the estimates could be recovered. 

For the second table, the degree of freedom can be recovered from the number of observations
and the number of predictors. If the residuals deviance are given then we could 
calculate the deviances and the $p$-values since the test statistic will also be known. 
On the other hand, we are given the residual deviances for the variables but not the NULL one, 
then we could not calculate the deviance of the first variable since it depends on the 
residual deviance of the NULL one. Furthermore, if the deviances are known then we
could not compute the residual one because the system of equation will be underdetermined.
Also, by the result of Exercise 1, the residual deviance D of the models can be 
determined by the responses $Y_i$ and the fitted canonical parameters $\hat{\theta}_i$ but 
since $\hat{\theta}_i = x_i^{T} \hat{\beta}$, we could recover $\hat{\theta}_i$
and therefore, the deviances of the models. And if the deviances are known, everything 
in the second table can be recovered. 

### d)
We use that option because the dispersion parameter $\phi$ is not known beforehand
It is not possible to derive what we would have obtained if we used the Chi-square test option
because the Chisquare test assumes that $\phi$ is known and the test statistics use 
$\phi$ instead of the estimated one in the $F$ test. 
### e) 
Since we have the dispersion parameter $\hat{\phi}$, the Pearson statistic $P$ can be 
derived as 
\[ P = \hat{\phi} (n - p - 1) = 0.001958 * (18 - 2 - 1) = 0.0029. \]
It is not possible to derive $\hat{W}$ because as we have shown in exercise 1,
the element $\hat{w}_{ij}$ of the working matrix $\hat{W}$ depends on the estimated
$\hat{\theta}_i$ which in turn depends on the input $x_i$. Since we do not know $x_i$ 
(not given in the question), we can not derive $\hat{w}_{ij}$. 



##  Question 3

### a)

```{r, echo=TRUE, include=TRUE}
data3=read.table("psi.txt",header=TRUE)
attach(data3)
```
The following table gives us some insight about the dataset. Note that the students that have not been instructed with the PSI method are, a priori, more expected to fail. This observation is supported by the difference in the passing rate of both groups. However, we still need more information to draw any conclusions.

```{r, echo=TRUE, include=TRUE}
n00 = length(data3$gpa[data3$passed == 0 & data3$psi == 0])
n01 = length(data3$gpa[data3$passed == 0 & data3$psi == 1])
n10 = length(data3$gpa[data3$passed == 1 & data3$psi == 0])
n11 = length(data3$gpa[data3$passed == 1 & data3$psi == 1])

percent0 = n10 / (n00 + n10); percent0
percent1 = n11 / (n01 + n11); percent1

table_data = matrix(c(n00,n01,n10,n11), ncol=2, byrow=TRUE)
colnames(table_data) = c('No PSI','PSI')
rownames(table_data) = c('Failed','Passed')
table=as.table(table_data)
table
```
The table below shows the mean of the students for each of the combinations of the binary variables 'passed' and 'psi'. The only significant difference is that the mean of the students that passed and did not have PSI is higher than the average grade of the students that passed and did have PSI. However, this could be due to the fact that only $3$ students passed. Probably, only the outstanding students managed.

```{r, echo=TRUE, include=TRUE}
m00 = mean(data3$gpa[data3$passed == 0 & data3$psi == 0]);
m01 = mean(data3$gpa[data3$passed == 0 & data3$psi == 1]);
m10 = mean(data3$gpa[data3$passed == 1 & data3$psi == 0]);
m11 = mean(data3$gpa[data3$passed == 1 & data3$psi == 1]);

table_data2 = matrix(c(m00,m01,m10,m11), ncol=2, byrow=TRUE);
colnames(table_data2) = c('No PSI','PSI');
rownames(table_data2) = c('Failed','Passed');
table2=as.table(table_data2);
table2
```
The following will give us more insight about the data. Note how the students that did have PSI have a higher average and also more variance. The plot suggests a better overall performance of the students with PSI.

```{r, echo=TRUE, include=TRUE}
boxplot(gpa~psi,data=data3,names=c("Without PSI","With PSI"), main='Box-plot of the average grade') 
```
Now, we can try different models and compare how they fit, after converting the variable 'psi' into a factor:

```{r, echo=TRUE, include=TRUE}
model3=glm(passed~gpa + psi,data=data3,family=binomial)
drop1(model3, test = 'Chisq')

anova(glm(passed~psi * gpa,data=data3,family=binomial), test="Chisq")
```
The default logistic model includes all the explanatory variables with their interaction terms. We 
then check if either of these variables is significant or not, including the interaction term.
Since the $p$-value of the interaction term is (> 0.05) non-significant,we can say that there is no interaction between the variables 'psi' and 'passed'. On the other hand, the $p$-values of both explanatory variables
are smaller than $0.05$ which mean that we can not dismiss them. Thus, a good model would be one that contains both explanatory variables.

### b)

```{r, echo=TRUE, include=TRUE}
summary(model3)
```
It can be seen that the estimated coefficients for the model are 
$\hat{\beta} = (\hat{\beta}_0, \hat{\beta}_1, \hat{\beta}_2) = (-11.6, 2.34, 3.06)$. 
It follows that the probability that a student with gpa equals to 3 who received psi
passes the assignment is 
\[ \frac{\exp{(-11.6 + 1\times2.34 + 3\times3.06)}}{1 + \exp{(-11.6 + 1\times2.34 + 3\times3.06)}} = 0.48.\]
For the student who does not receive psi: 
\[ \frac{\exp{(-11.6 + 0\times2.34 + 3\times3.06)}}{1 + \exp{(-11.6 + 0\times2.34 + 3\times3.06)}} = 0.08.\]
Thus, it can be seen that having psi positively affect the passing probability, 
which is evident from the positive coefficient of psi. 
### c)
The odd is 
\[ o = \frac{P(passes)}{P(fails)} = \exp{(-11.6 + 2.34 + gpa \times 3.06)}. \]
This number means that the probability of passing is $o$ times as big as the probability 
of failing. So the bigger the odd, the higher the probability of passing. 
When $gpa$ increases in one unit, the odd is multiplied by $e^{3.06}$, 
which is larger than 1 so this means that the higher the $gpa$, 
the more likely the probability of passing. Thus, this number is dependent on $gpa$. 
For an estimate of the odd, we calculate the mean of the $gpa$, which is $3.12$
then the odd is $\exp{(-11.6 + 2.34 + 3.12 \times 3.06)}$

## Question 4


```{r, echo=TRUE, include=FALSE}
data4=read.table("awards.txt",header=TRUE)
data4$prog = as.factor(data4$prog)
attach(data4)
```
### a)
We first build the model without taking $math$ into account using Poisson regression. 
```{r, echo=TRUE, include=TRUE}
model4=glm(num_awards~prog,data=data4,family=poisson)
anova(model4,test="Chisq")
```
The results for the ANOVA with the Chi Squared test yield a significant ($< 0.05$) $p$-value for the factor $prog$.
```{r, echo=TRUE, include=TRUE}
summary(model4);
```
```{r, echo=TRUE, include=TRUE}
o1 = predict(model4, newdata=data.frame(prog=factor(1)), se.fit=TRUE);
exp(o1$fit)
o2 = predict(model4, newdata=data.frame(prog=factor(2)), se.fit=TRUE);
exp(o2$fit)
o3 = predict(model4, newdata=data.frame(prog=factor(3)), se.fit=TRUE);
exp(o3$fit)
```
It can be seen that the second program has the most award $1.17 > 0.9 > 0.57$. Thus,
it is the best for this model.
### b)

Now we are taking into account the variable $math$ for our model. When performing the first test, we notice that the interaction term between the factor 'prog' and the variable 'math' does not turn out to be relevant. Checking the AIC values for the models we. note that indeed the model that excludes interaction term seems to work better. Therefore, we decide to drop that term.

```{r, echo=TRUE, include=TRUE}
model4_1=glm(num_awards~prog*math,data=data4,family=poisson)
anova(model4_1, test = 'Chisq')
drop1(model4_1)
```
Now we need to check the significance of our new model. It can be seen that both 
of the $p$-values of $prog$ and $math$ are smaller than 0.05 so those two variables 
are important to the model. 

```{r, echo=TRUE, include=TRUE}
model4_2=glm(num_awards~prog+math,data=data4,family=poisson)
drop1(model4_2, test = 'Chisq')
```
To compute $95\%$-confidence intervals, we first need to obtain the Covariance matrix to compute our confidence intervals. By default, this is done. in R by taking the Normal quantiles. However, we opt to be more conservative and not make any extra assumptions by computing it with. $t$-quantiles. The. resulting interval for each of the coefficients of the model is provided below.

```{r, echo=TRUE, include=TRUE}
confint(model4_2, level=0.95)
```

### c)
```{r, echo=TRUE, include=TRUE}
summary(model4_2)
```
Since the link function is $log$, which is an increasing monotonic function so 
an increase in an input will result in an increase in the output. Also, 
the estimated coefficients are $\hat{\beta} = (-2.37, 0.45, 0.56, 0.036) = (program1, program2, program3, math)$. Since the coefficient of $program3$ is the highest, it follows that the number of awards from
$program3$ is highest as well. 

```{r, echo=TRUE, include=TRUE}
out = predict(model4_2, newdata=data.frame(prog=factor(1), math=55), type="response", se.fit=TRUE)
exp(out$fit)
out = predict(model4_2, newdata=data.frame(prog=factor(2), math=55), type="response", se.fit=TRUE)
exp(out$fit)
out = predict(model4_2, newdata=data.frame(prog=factor(3), math=55), type="response", se.fit=TRUE)
exp(out$fit)
```
The number of awards for the vocational program and math score 55 is 1.05. To confirm the 
previous result, the number of awards for the academic program is 1.17, highest among
all programs. 

### d)
We can see that the Pearson chi-squared statistic $P = 179.07$ and the deviance
$D = 198.04$. It can be seen that the two values differ quite a bit which 
can indicate that the model does not fit the data well. 

```{r, echo=TRUE, include=TRUE}
P=sum(residuals(model4_2,type="pearson")^2)
D=deviance(model4_2)
P
D
```

### e)
To check for overdispersion, we check both 
\[ \tilde{\phi} = \frac{D}{n - p - 1} \]
and 
\[ \hat{\phi} = \frac{P}{n - p -1} \]
to see if they are smaller than 1 or not.

```{r, echo=TRUE, include=TRUE}
D/df.residual(model4_2);
P/df.residual(model4_2);
```
Since $\tilde{\phi} = 1.01 > 1$, we can say that there is an overdispersion problem. 















