---
title: "Assignment 4"
output:
  pdf_document:
    includes:
      in_header: preample.tex
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
library(knitr)
library(afex)
library(performance)
library(magrittr)
library(datasets)
library(MASS)
library(ggplot2)
library(quantmod)
library(plyr)
library(EnvStats)
hook_output <- knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    n <- as.numeric(n)
    x <- unlist(stringr::str_split(x, "\n"))
    nx <- length(x) 
    x <- x[pmin(n,nx)]
    if(min(n) > 1)  
      x <- c(paste(options$comment, "[...]"), x)
    if(max(n) < nx) 
      x <- c(x, paste(options$comment, "[...]"))
    x <- paste(c(x, "\n"), collapse = "\n")
  }
  hook_output(x, options)
    })
```

### Question 1
#### a)
We have $\ex(X_t) = \ex(Y - 2Z_{t-1} + Z_t)$ and since $Y$ is independent of $\{Z_t\}$,
it follows that 
\[ \ex(X_t) = \ex(Y - 2Z_{t-1} + Z_t) = \ex(Y) - 2\ex(Z_{t-1} + \ex(Z_t)) = 1.\]
Furthermore, 
\[ \ex(X_t X_{t + h}) = \ex((Y - 2Z_{t-1} + Z_t) (Y - 2Z_{t + h - 1} + Z_{t+h}))
= \ex(Y^2) = \text{Var}(Y) - \ex(Y)^2 = 0
\]
because in the expansion, any term with $Z_{t + k}$ will have 0 expectation. Thus, 
$\{ X_t \}$ is stationary. We can see that $\{ Y_t \}$ is not stationary because 
$X_t$ depends on $t$ and thus, $\ex(Y_t)$ depends on $t$. 

#### b) 
We have $\nabla_d (W_t + 1) = W_t + 1 - W_{t-d} - 1 = W_t - W_{t-d}$ so it follows 
that 
\begin{align*}
  \nabla_d^2 (W_t + 1) &= \nabla_d(W_t - W_{t-d})\\
  &= W_t - W_{t - d} - W_{t-d} + W_{t-2d}\\
  &= W_t - 2W_{t-d} + W_{t-2d}\\
  &= at^2 + bts_t + X_t - 2(a(t-d)^2 +  b(t-d)s_t + X_{t-d}) + a(t-2d)^2 + b(t-2d)s_t + X_{t-2d}\\
  &= a(t^2 - 2t^2 + 4dt - 2d^2 + t^2 - 4dt + 4d^2) + bs_t(t - 2t + 2d + t - 2d) + X_t - 2X_{t-d} + X_{t-2d}\\
  &= ad^2 + bs_t 0 + X_t - 2X_{t-d} + X_{t-2d} = ad^2 + X_t - 2X_{t-d} + X_{t-2d}.
\end{align*}
If $\{X_t\}$ is stationary then $Y_t = ad^2 + (X_t - X_{t-d}) - (X_{t-d} - X_{t-2d})$ 
is also stationary because $\{ (X_t - X_{t-d}) \}$ and $\{ (X_{t-d} - X_{t-2d}) \}$ 
are stationary. 


### Question 2
#### a) 
Note that $aY_{t-1} = 2aX_{t-1} - aX_{t-2}$ so 
\begin{align*}
aY_t &= 2aX_t - aX_{t-1}\\
&= 2a(0.2X_{t-1} + Z_t - Z_{t-1}) - a(0.2X_{t-2} + Z_{t-1} - Z_{t-2})\\
&= 0.4aX_{t-1} - 0.2aX_{t-2} - aZ_{t-1} +aZ_{t-2} + 2aZ_t\\
&= \frac{1}{5} (2aX_{t-1} - aX_{t-2}) - aZ_{t-1} +aZ_{t-2} + 2aZ_t\\
&= \frac{1}{5} aY_{t-1} - aZ_{t-1} +aZ_{t-2} + 2aZ_t.
\end{align*}
Let $a = 1/2$, we have 
\[ aY_t = \frac{1}{5} aY_{t-1} - aZ_{t-1} +aZ_{t-2} + Z_t \] 
so $\{ aY_t \}$ follows an ARMA(p, q) model for $a = 1/2$, $\alpha_1 = 1/5$, $\beta_{1} = \beta_{2} = a$, $p = 1$, and $q = 2$. 

#### b) 
We have 
\begin{align*}
\text{Cov}(X_t, Z_t) &= \ex[(X_t - \ex(X_t))(Z_t - \ex(Z_t))]\\
&=\ex[(X_t - \ex(X_t))Z_t]\\
&= \ex(X_t Z_t) - \ex[Z_t \ex(X_t)]. 
\end{align*}
Assuming that $\{X_t\}$ is stationary, 
\[ \text{Cov}(X_t, Z_t) = \ex(X_t Z_t) - \ex[Z_t \ex(X_t)] = \ex(X_t Z_t) - \ex(Z_t)\ex(X_t)\]
so 



### Question 3
#### a) 
The autocovariance function 
\[ \gamma_Z(h) = \begin{cases} \sigma^2 \text{ for $h = 0$} \\ 0 \;\;\text{ for $h \neq 0$}     \end{cases}\]
then the spectral density
\[ f_Z(\lambda) = \frac{1}{2\pi} \sum_{h \in \mathbb{Z}} \gamma_Z(h) e^{-ih\lambda} 
= \frac{1}{2\pi} \sigma^2. \]

#### b) 
$\{ X_t \}$ is an MA(q) time series by introducing new WN $Z^{'}_{t} = Z_{t + 1}$ 
We have 
\[ \ex(X_t) = \ex\left(\frac{1}{2} Z_{t+1} + Z_t - \frac{1}{2}Z_{t-1} \right) = \frac{1}{2} 
\ex(Z_{t+1}) + \ex(Z_t) - \frac{1}{2} \ex(Z_{t-1}) = \sigma^2
\]
not dependent on $t$. Doing the same thing for $\ex(X_t X_{t+h})$ to see that the 
expansion only contains $Z_t$ terms so it is also independent of $t$. Thus, $\{ X_t \}$
is stationary.

The autocovariance function 
\[\gamma_{X}(h) = \begin{cases}\sigma^2\sum_{i=0}^{2 - h} \beta_i \beta_{i+h} & \text{ $h=0,1,\dots,2,$} \\
\gamma_X(-h) & h = -1,\dots,-2,\\
0, & \text{otherwise}
\end{cases}\]
and the spectral density 
\begin{align*}
f_X(\lambda) &= \frac{1}{2\pi} \sum_{h \in \mathbb{Z}} \gamma_X(h) e^{-ih\lambda}\\
&=\frac{1}{2\pi} \sum_{h = -2}^{2} \gamma_X(h) e^{-ih\lambda}\\
&= \frac{1}{2\pi} \left(\sum_{h = -2}^{-1} \gamma_X(h)e^{-ih\lambda} + \sum_{h = 0}^{2} \gamma_X(h)e^{-ih\lambda}   \right)\\
&= \frac{1}{2\pi} \left(\gamma_X(2)e^{i2\lambda} + \gamma_X(1)e^{i\lambda}  + \sum_{h = 0}^{2} \gamma_X(h)e^{-ih\lambda}   \right)\\
\end{align*}


#### c)
$\{ X_t \}$ is a linear transformation of $\{ Z_t \}$ because 
$X_t = \frac{1}{2} Z^{'}_{t} + Z^{'}_{t-1} - \frac{1}{2}Z^{'}_{t-2}$ which is a 
linear combination of $\{ Z^{'}_t \}$ by letting $Z^{'}_t = Z_{t + 1}.$ 
The corresponding filter coefficients $\psi_0 = 1/2$, $\psi_1 = 1$, $\psi_2 = -1/2$, 
and $\psi_k = 0$ for $k \notin \{ 0,1,2\}$. The transfer function 
\[ \psi(\lambda) = \sum_{j} \psi_j e^{-ij\lambda} = \frac{1}{2} + e^{-i\lambda} - \frac{1}{2} e^{-2\lambda i}. \]





### Question 4
### a) 
Let $n = 100$, $p = 2$, and $q = 1$ with $\alpha_1 = \alpha_2 = 0.1$, $\beta_1 = 1$
then the plot of the time series is 
```{r, include=TRUE, echo=TRUE}
arma1=arima.sim(100,model=list(ar=c(0.1,0.1),ma=1))
plot(arma1,ylab="",main="ARMA(2,1), a1=a2=0.1,b1=1")
```
We then find the estimates of the model's parameters.

```{r, echo=TRUE, include=TRUE}
arma1.mle = arima(arma1,order=c(2,0,1),method="ML",include.mean=F);
arma1.mle
```
The estimated parameters are $\hat{\alpha_1} = 0.16$, $\hat{\alpha_2} = 0.088$, and 
$\hat{\beta_1} = 0.947$ which are pretty different from the true ones. The residuals
plot is 
```{r, echo=TRUE, include=TRUE}
plot(arma1.mle$residuals)
```
There is no visible pattern to the residual plot which suggests that the estimated
coefficients are appropriate. We use the Portmanteau test to evaluate the quality 
of the fit 
```{r, echo=TRUE, include=TRUE}
Box.test(resid(arma1.mle),type="Box-Pierce")$p.value

```
The returned $p$-value is $0.792$ which suggests an ok fit. 

#### b)
We fit an AR(2) model.
```{r, echo=TRUE, include=TRUE}
ar(x=arma1, order.max = 2, method=c("yw"))
```
The Yule-Walker estimates of the parameters are $\hat{\alpha_1} = 0.86$ and $\hat{\alpha_2} = -0.38$
which are very different from that of $(a)$. The Portmanteau test returns 
a $p$-value of $0.42$ which suggests that this is a good fit but since the estimated
parameters from this method are more dissimilar with the true values compared to the ML-estimated ones
so the quality of these estimates are not as good as that of a). 
```{r, echo=TRUE, include=TRUE}
Box.test(ar(x=arma1, order.max = 2)$resid,type="Box-Pierce")$p.value
```

### Question 5
#### a)
The plot of $mdeaths$ and $fdeaths$ is
```{r, echo=TRUE, include=TRUE}
plot.ts(mdeaths, type='l', col="red", ylim=c(300, 3000), ylab="deaths")
lines(fdeaths, type="l", col="blue")
legend("topright", legend=c("mdeaths", "fdeaths"), 
       col=c("red", "blue"), 
       lty=1)
```
We can also decompose the time series into its components. The decomposition for 
$mdeaths$ is:
```{r, echo=TRUE, include=TRUE}
decompm=decompose(mdeaths);
plot(decompm)
```
And the decomposition of $fdeaths$ is
```{r, echo=TRUE, include=TRUE}
decompf=decompose(fdeaths);
plot(decompf)
```
It can be seen that there exists seasonality in the two datasets since the number 
of deaths of both genders spike every year at the beginning of the year. One obvious 
difference between the two datasets is that the $mdeaths$ is far higher than $fdeaths$ 
(male oppression). Furthermore, for both datasets, there seems to be a faint downward 
trend of the number of deaths but this trend is stronger in $mdeaths$ than $fdeaths$. 


#### b) 
For this part, we only consider $mdeaths$, the plot of the time series $mdeaths$
with its smoothing spline is 

```{r, echo=TRUE, include=TRUE}
plot.ts(mdeaths, type='l', col="red", ylim=c(300, 3000), 
        ylab="deaths", main="spar=0.4")
sm = smooth.spline(x=mdeaths, spar=0.4)
lines(sm, col="blue", lwd=2)
```
We then subtract the spline from the original time series to obtain a time series
with no trend or seasonality. 
```{r, echo=TRUE, include=TRUE}
md_rs = mdeaths - sm$y;
plot.ts(md_rs)
```
We then plot an estimate of the autocorrelation function on the de-trended
and de-seasonalized time series. 
```{r, echo=TRUE, include=TRUE}
acf(md_rs)
```
Since the ACF is mostly small, this confirms the fact that we are dealing with a 
de-trended and de-seasonalized time series. For $p \in \{0,\dots,5 \}$
and $q \in \{0,\dots,5 \}$, we fit different ARMA(p, q) models to the de-trended
and de-seasonalized time series and obtain the best one. Different combinations 
of $p$ and $q$ and their corresponding ARMA(p, q) model's AIC are listed below. 

```{r, echo=TRUE, include=TRUE}
for (p in c(1:5)) {
  for (q in c(1:5)) {
    
    print(c(p, q, arima(md_rs,order=c(p,0,q),method="ML",include.mean=F)$aic))
  }
}
```
It can be seen that the $(p,q)$ value with the minimum AIC score is $(4,5)$ with
an AIC score of 842. 

#### d)
```{r, echo=TRUE, include=TRUE}
mdeaths_c = mdeaths[1:60];
year = index(mdeaths)[1:60];
yearsq=year^2;
```
Using the (fractional) year as time, we estimate the trend by a quadratic function 
of time. 

```{r, echo=TRUE, include=TRUE}
trend_md = lm(mdeaths_c~year+yearsq);
trend_md$coef
```

### Question 6
#### a)

The first step to get use the MACD method is to obtain the data. It is important to note that we are requested MACD and Signal lines to be defined for two specific dates. Hence, we need the data starting from earlier than the desired date. By trial and error we checked that we need our data to start on "2021-11-19".

```{r, echo=TRUE, include=TRUE}
library('TTR')
library(quantmod)
getSymbols("AAPL",from="2021-11-19",to="2022-11-19")
stock=AAPL
```
Moving on, we now choose our parameters for MACD: $S=12$, $L=26$ and $K=9$. We can also check the numnber of NA values in the column Signal, for this column is the one that will have more NA's. A manual check has sufficed to check that indeed the first day for which both columns are defined is the desired date.

```{r, echo=TRUE, include=TRUE}
macd<-MACD(Cl(stock),nFast=12,nSlow=26,nSig=9,percent=FALSE)
n.na=sum(is.na(macd$signal))
n.na # OK
```
#### b)

Before visualizing the data, we first will create a new table, for which we will have no NA values and, more importantly, we only have the data we care about. Afterwards, we will visualize a plot of the stock's price:

```{r, echo=TRUE, include=TRUE}
# trim
t1=time(macd[n.na+1,]); t1 #=time(macd[nSlow+nSig-1,]) # row 34=26+9-1 
macd2=macd[time(macd)>=t1] # macd2 starting from the date t1

plot(Cl(stock))  # plot of the closing prices of the stock
```
Also, we can visualize in a same plot our valiues for MACD (red) and Signal (blue), paying special attention to the points where the two lines cross each other. 

```{r, echo=TRUE, include=TRUE}
plot(macd2$macd, col ="red") # plot of MACD line
lines(macd2$signal,col="blue") # plot of Signal line
```

#### c)

We now have to simulate how much benefit or loss we would have obtained by trading the stock on the crossings between the MACD line and Signal line. We start with an initial capital of $172.17$, but note that we do not buy the stock inmediately. In fact, we wait untill the Signal line crosses the MACD line from above to below. After that, we keep on following the strategy and, in the end, we sell the stock in the last day.

By trading on the line crossings, we managed to obtain a benefit of $30.36$ and we still have the stock, which is worth $151.29$. This adds up to a total final capital of $181.65$. Of course, we still need to our initial capital, and we will see we have a final gain of $9.48$.

```{r, echo=TRUE, include=TRUE}
price<-as.numeric(Cl(stock[time(stock)>=t1]))
n=length(price)
gain1=price[n]-price[1]; gain1 # gain without using any trading strategy
buy<-as.numeric(ifelse(macd2$macd < macd2$signal,1,-1))

gain = price[1] # however, note we still don't buy it
for (i in 1:219) {
  j = i+1
  if (buy[i] == 1 && buy[j] == -1) {
    gain = gain - price[j] #buy stock
  } else if (buy[i] == -1 && buy[j] == 1) {
    gain = gain + price[j] #sell stock
  }
}
gain; price[n]

final_capital = gain + price[n]
final_gain = final_capital - price[1]

final_capital; final_gain
```
#### d)

Very easily, we can check that the trivial strategy of buying, holding and selling does not seem to be beneficial for this stock at this particular time. In fact, one would have lost $-20.88$, which is worse than not investing at all. 

It is important to remark that here we are not taking into account the fees and comissions that apply to every time we buy or sell an asset. This would make the final gain be even lower and, probably, negative.









